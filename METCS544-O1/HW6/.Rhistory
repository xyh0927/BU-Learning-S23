install.packages("stringr")
library(stringr)
file <- "https://people.bu.edu/kalathur/datasets/mlk.txt"
words <- scan(file, what=character())
# detect words with punctuation symbols
words_with_punct <- words[str_detect(words, "[[:punct:]]")]
# show the words with punctuation symbols
words_with_punct
library(stringr)
#part1
file <- "https://people.bu.edu/kalathur/datasets/mlk.txt"
#a
words <- scan(file, what=character())
words_with_punct <- words[str_detect(words, "[[:punct:]]")]
words_with_punct
# replace punctuation with empty string and convert to lower case
new_words <- tolower(str_replace_all(words, "[[:punct:]]", ""))
# show the first 10 words in the new dataset
head(new_words, 10)
# find the top 5 frequent words
top_words <- names(sort(table(new_words), decreasing=TRUE)[1:5])
# show the top 5 frequent words
top_words
#d
library(ggplot2)
word_lengths <- table(str_length(new_words))
ggplot(data=data.frame(length=names(word_lengths), count=word_lengths),
aes(x=length, y=count)) +
geom_bar(stat="identity") +
ggtitle("Distribution of Word Lengths")
#part1
file <- "https://people.bu.edu/kalathur/datasets/mlk.txt"
#a
words <- scan(file, what=character())
punct_words <- words[str_detect(words, "[[:punct:]]")]
punct_words
#b
new_words <- str_replace_all(words, "[[:punct:]]", "") %>% tolower()
new_words
freq_words <- table(new_words)
top_words <- sort(freq_words, decreasing = TRUE)[1:5]
top_words
#d
word_lengths <- str_length(new_words)
freq_lengths <- table(word_lengths)
barplot(freq_lengths, main = "Frequency of word lengths in new_words", xlab = "Word length", ylab = "Frequency")
longest_words <- new_words[which.max(nchar(new_words))]
longest_words
c_words <- str_subset(new_words, "^c")
c_words
r_words <- str_subset(new_words, "r$")
r_words
cr_words <- str_subset(new_words, "^c.*r$")
cr_words
#c
stopfile <- "https://people.bu.edu/kalathur/datasets/stopwords.txt"
stopwords <- scan(stopfile, what=character())
new_words_clean <- new_words[!(new_words %in% stopwords)]
freq_words_clean <- table(new_words_clean)
top_words_clean <- sort(freq_words_clean, decreasing = TRUE)[1:5]
top_words_clean
word_lengths_clean <- str_length(new_words_clean)
freq_lengths_clean <- table(word_lengths_clean)
barplot(freq_lengths_clean, main = "Frequency of word lengths in new_words_clean", xlab = "Word length", ylab = "Frequency")
#e
longest_words <- new_words[which.max(nchar(new_words))]
longest_words
#f
c_words <- str_subset(new_words, "^c")
c_words
#g
r_words <- str_subset(new_words, "r$")
r_words
#h
cr_words <- str_subset(new_words, "^c.*r$")
cr_words
library(stringr)#for part 1
library(tidyverse)#for part 2
install.packages("tidyverse")
install.packages("gargle")
install.packages("httr")
install.packages("curl")
install.packages("curl")
library(tidyverse)#for part 2
install.packages("httr")
install.packages("gargle")
install.packages("rvest")
install.packages("googledrive")
install.packages("googlesheets4")
install.packages("tidyverse")
install.packages("systemfonts")
install.packages("systemfonts")
install.packages("textshaping")
install.packages("textshaping")
install.packages("ragg")
install.packages("ragg")
install.packages("tidyverse")
library(tidyverse)#for part 2
#a
usaDailyTemps <- read.csv("usa_daily_avg_temps.csv") %>% as_tibble()
usaDailyTemps <- read.csv("https://people.bu.edu/kalathur/usa_daily_avg_temps.csv") %>% as_tibble()
usaDailyTemps
maxTempsByYear <- usaDailyTemps %>% group_by(year) %>% summarize(maxTemp = max(avg_temp))
library(tidyverse)
usaDailyTemps_df <- read.csv("https://people.bu.edu/kalathur/usa_daily_avg_temps.csv")
usaDailyTemps <- as_tibble(usaDailyTemps_df)
usaDailyTemps <- as_tibble(usaDailyTemps_df)
usaDailyTemps
maxTempsByYear <- usaDailyTemps %>%
group_by(year) %>%
summarize(max_temp = max(avg_temp, na.rm = TRUE))
#a
usaDailyTemps <-as_tibble(df)
df <- read.csv("http://people.bu.edu/kalathur/usa_daily_avg_temps.csv")
usaDailyTemps <-as_tibble(df)
usaDailyTemps
max_temp <- usaDailyTemps %>% group_by(year) %>% summarise(max = max(avgtemp))
View(max_temp)
max_temp
ggplot(data = max_temp, aes(x=year, y=max, group=1))+
geom_line()+
geom_point()+ggtitle("Year-wise Max Temperatures recorded")+
scale_x_continuous(breaks = (seq(min(max_temp$year), max(max_temp$year), by = 1)))+
theme(axis.text.x = element_text(angle = 45, hjust = 1))
max_temp_yr <- usaDailyTemps %>% group_by(year) %>% summarise(max = max(avgtemp))
max_temp_yr
ggplot(data = max_temp_yr, aes(x=year, y=max, group=1))+
geom_line()+
geom_point()+ggtitle("Year-wise Max Temperatures recorded")+
scale_x_continuous(breaks = (seq(min(max_temp_yr$year), max(max_temp_yr$year), by = 1)))+
theme(axis.text.x = element_text(angle = 45, hjust = 1))
max_temp_state <- usaDailyTemps %>% group_by(state) %>% summarise(max = max(avgtemp))
print("Maximum temperature recorded for each state")
print(max_temp_state)
ggplot(data = max_temp_state, aes(x=state, y=max, group=1))+
geom_bar(stat = 'identity')+
ggtitle("State-wise Max Temperatures recorded")+
theme(axis.text.x = element_text(angle = 45, hjust = 1))
#c
max_temp_state <- usaDailyTemps %>% group_by(state) %>% summarise(max = max(avgtemp))
max_temp_state
ggplot(data = max_temp_state, aes(x=state, y=max, group=1))+
geom_bar(stat = 'identity')+
ggtitle("State-wise Max Temperatures recorded")+
theme(axis.text.x = element_text(angle = 45, hjust = 1))
bostonDailyTemps <- filter(usaDailyTemps, city == 'Boston')
bostonDailyTemps
#e
avg_temp_mon <- bostonDailyTemps %>% group_by(month) %>% summarise(average_temp = mean(avgtemp))
avg_temp_mon
ggplot(data = avg_temp_mon, aes(x=month, y=average_temp, group=1))+
geom_line()+
ggtitle("Max Temperatures recorded Month-wise in Boston")+
scale_x_continuous(breaks = (seq(min(avg_temp_mon$month), max(avg_temp_mon$month), by = 1)))
b
#b
max_temp_yr <- usaDailyTemps %>% group_by(year) %>% summarise(max = max(avgtemp))
max_temp_yr
ggplot(data = max_temp_yr, aes(x=year, y=max, group=1))+
geom_line()+
geom_point()+ggtitle("plot of maximum temperatures recorded for each year?")+
scale_x_continuous(breaks = (seq(min(max_temp_yr$year), max(max_temp_yr$year), by = 1)))+
theme(axis.text.x = element_text(angle = 45, hjust = 1))
#b
max_temp_yr <- usaDailyTemps %>% group_by(year) %>% summarise(max = max(avgtemp))
max_temp_yr
ggplot(data = max_temp_yr, aes(x=year, y=max, group=1))+
geom_line()+
geom_point()+ggtitle("plot of maximum temperatures recorded for each year")+
scale_x_continuous(breaks = (seq(min(max_temp_yr$year), max(max_temp_yr$year), by = 1)))+
theme(axis.text.x = element_text(angle = 45, hjust = 1))
#c
max_temp_state <- usaDailyTemps %>% group_by(state) %>% summarise(max = max(avgtemp))
max_temp_state
ggplot(data = max_temp_state, aes(x=state, y=max, group=1))+
geom_bar(stat = 'identity')+
ggtitle("plot of maximum temperatures recorded for each state")+
theme(axis.text.x = element_text(angle = 45, hjust = 1))
#e
avg_temp_mon <- bostonDailyTemps %>% group_by(month) %>% summarise(average_temp = mean(avgtemp))
avg_temp_mon
ggplot(data = avg_temp_mon, aes(x=month, y=average_temp, group=1))+
geom_line()+
ggtitle("plot of average monthly temperatures for Boston")+
scale_x_continuous(breaks = (seq(min(avg_temp_mon$month), max(avg_temp_mon$month), by = 1)))
library(stringr)#for part 1
#part1
file <- "https://people.bu.edu/kalathur/datasets/mlk.txt"
#a
words <- scan(file, what=character())
punct_words <- words[str_detect(words, "[[:punct:]]")]
punct_words
#b
new_words <- str_replace_all(words, "[[:punct:]]", "") %>% tolower()
new_words
#c
stopfile <- "https://people.bu.edu/kalathur/datasets/stopwords.txt"
stopwords <- scan(stopfile, what=character())
new_words_clean <- new_words[!(new_words %in% stopwords)]
freq_words_clean <- table(new_words_clean)
top_words_clean <- sort(freq_words_clean, decreasing = TRUE)[1:5]
top_words_clean
#d
word_lengths_clean <- str_length(new_words_clean)
freq_lengths_clean <- table(word_lengths_clean)
barplot(freq_lengths_clean, main = "Frequency of word lengths in new_words_clean", xlab = "Word length", ylab = "Frequency")
#e
longest_words <- new_words[which.max(nchar(new_words))]
longest_words
#f
c_words <- str_subset(new_words, "^c")
c_words
#g
r_words <- str_subset(new_words, "r$")
r_words
#h
cr_words <- str_subset(new_words, "^c.*r$")
cr_words
#part2
library(tidyverse)
df <- read.csv("http://people.bu.edu/kalathur/usa_daily_avg_temps.csv")
#a
usaDailyTemps <-as_tibble(df)
usaDailyTemps
#b
max_temp_yr <- usaDailyTemps %>% group_by(year) %>% summarise(max = max(avgtemp))
max_temp_yr
ggplot(data = max_temp_yr, aes(x=year, y=max, group=1))+
geom_line()+
geom_point()+ggtitle("plot of maximum temperatures recorded for each year")+
scale_x_continuous(breaks = (seq(min(max_temp_yr$year), max(max_temp_yr$year), by = 1)))+
theme(axis.text.x = element_text(angle = 45, hjust = 1))
#c
max_temp_state <- usaDailyTemps %>% group_by(state) %>% summarise(max = max(avgtemp))
max_temp_state
ggplot(data = max_temp_state, aes(x=state, y=max, group=1))+
geom_bar(stat = 'identity')+
ggtitle("plot of maximum temperatures recorded for each state")+
theme(axis.text.x = element_text(angle = 45, hjust = 1))
#d
bostonDailyTemps <- filter(usaDailyTemps, city == 'Boston')
bostonDailyTemps
#e
avg_temp_mon <- bostonDailyTemps %>% group_by(month) %>% summarise(average_temp = mean(avgtemp))
avg_temp_mon
ggplot(data = avg_temp_mon, aes(x=month, y=average_temp, group=1))+
geom_line()+
ggtitle("plot of average monthly temperatures for Boston")+
scale_x_continuous(breaks = (seq(min(avg_temp_mon$month), max(avg_temp_mon$month), by = 1)))
